{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae96752c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import cv2\n",
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1845d656",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Configuration for Local Environment ---\n",
    "PROJECT_ROOT = os.getcwd() # Assumes you run this from the project folder\n",
    "ZIP_FILE_NAME = r'YOLO_URBAN_ISSUES_DATASET.zip'\n",
    "DATASET_PATH = os.path.join(PROJECT_ROOT, r'YOLO_URBAN_ISSUES_DATASET')\n",
    "ZIP_FILE_PATH = os.path.join(PROJECT_ROOT, ZIP_FILE_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "26d78168",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset already found and ready at: d:\\Projects\\Sahaay\\YOLO_URBAN_ISSUES_DATASET\n"
     ]
    }
   ],
   "source": [
    "# Check if the dataset is already unzipped\n",
    "if not os.path.exists(DATASET_PATH):\n",
    "    print(f\"Dataset not found at {DATASET_PATH}. Starting unzipping process...\")\n",
    "    \n",
    "    if os.path.exists(ZIP_FILE_PATH):\n",
    "        try:\n",
    "            with zipfile.ZipFile(ZIP_FILE_PATH, 'r') as zip_ref:\n",
    "                # Extract all contents to the PROJECT_ROOT\n",
    "                zip_ref.extractall(PROJECT_ROOT)\n",
    "            print(f\"Successfully extracted {ZIP_FILE_NAME} to {PROJECT_ROOT}.\")\n",
    "            \n",
    "            # --- IMPORTANT: Standardize Folder Name ---\n",
    "            # Check for a common issue: the zip creates a directory named after the file.\n",
    "            possible_unzip_name = ZIP_FILE_NAME.replace('.zip', '')\n",
    "            possible_unzip_path = os.path.join(PROJECT_ROOT, possible_unzip_name)\n",
    "\n",
    "            if os.path.exists(possible_unzip_path) and not os.path.exists(DATASET_PATH):\n",
    "                os.rename(possible_unzip_path, DATASET_PATH)\n",
    "                print(f\"Renamed {possible_unzip_name} to {os.path.basename(DATASET_PATH)}\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error during unzipping: {e}\")\n",
    "            \n",
    "    else:\n",
    "        print(f\"Error: ZIP file not found at {ZIP_FILE_PATH}. Please ensure '{ZIP_FILE_NAME}' is in the project root.\")\n",
    "\n",
    "else:\n",
    "    print(f\"Dataset already found and ready at: {DATASET_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6aa50638",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration file 'data.yaml' confirmed with val path: images/val\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# --- Configuration ---\n",
    "# Your verified absolute path (which seems correct now)\n",
    "YOUR_VERIFIED_ABSOLUTE_PATH = r' D:/Projects/SIH/YOLO_URBAN_ISSUES_DATASET/YOLO_URBAN_ISSUES_DATASET' \n",
    "# ---------------------\n",
    "\n",
    "# Define the content for the YOLO configuration file\n",
    "yaml_content = f\"\"\"\n",
    "# YOLOv8 custom data configuration\n",
    "path: {YOUR_VERIFIED_ABSOLUTE_PATH}\n",
    "train: images/train\n",
    "val: images/val # <-- ENSURE THIS IS 'val'\n",
    "\n",
    "# Number of classes\n",
    "nc: 9\n",
    "\n",
    "# Class names based on your description\n",
    "names:\n",
    "  0: Damaged concrete structures\n",
    "  1: DamagedElectricalPoles\n",
    "  2: DamagedRoadSigns\n",
    "  3: DeadAnimalsPollution\n",
    "  4: FallenTrees\n",
    "  5: Garbage\n",
    "  6: Graffitti\n",
    "  7: IllegalParking\n",
    "  8: Potholes and RoadCracks\n",
    "\"\"\"\n",
    "\n",
    "yaml_file_path = 'data.yaml'\n",
    "with open(yaml_file_path, 'w') as f:\n",
    "    f.write(yaml_content)\n",
    "\n",
    "print(f\"Configuration file '{yaml_file_path}' confirmed with val path: images/val\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c637dd4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset folder not found at the suspected locations.\n",
      "   Please manually check where the 'urban_datasets.zip' file extracted.\n",
      "If it extracted to your current directory, try: d:\\Projects\\Sahaay\\urban_issues_dataset\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# --- 1. Define the suspected root directory based on your error message ---\n",
    "# This is the full path where your unzipped dataset folder should be located.\n",
    "# We will use the path shown in your error message, but you might need to adjust it\n",
    "# if the unzipping created a different folder name (e.g., 'urban_issues_dataset').\n",
    "\n",
    "# Check for the two most common unzipped folder names:\n",
    "possible_paths = [\n",
    "    r'D:/Projects/SIH/YOLO_URBAN_ISSUES_DATASET/YOLO_URBAN_ISSUES_DATASET', # Path seen in the error message\n",
    "    r'D:/Projects/SIH/urban_issues_dataset',     # Path suggested in previous steps\n",
    "]\n",
    "\n",
    "found_path = None\n",
    "for p in possible_paths:\n",
    "    if os.path.isdir(p):\n",
    "        found_path = p\n",
    "        break\n",
    "\n",
    "if found_path:\n",
    "    print(f\"FOUND DATASET AT: {found_path}\")\n",
    "    print(f\"   Please use this path for the 'path:' variable in your YAML file.\")\n",
    "else:\n",
    "    print(\"Dataset folder not found at the suspected locations.\")\n",
    "    print(\"   Please manually check where the 'urban_datasets.zip' file extracted.\")\n",
    "    # Fallback to current working directory assumption\n",
    "    print(f\"If it extracted to your current directory, try: {os.path.join(os.getcwd(), 'urban_issues_dataset')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e6961891",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Checking Training Images Directory ---\n",
      "ERROR: Training Images directory does not exist at: D:\\Projects\\SIH\\YOLO_URBAN_ISSUES_DATASET\\YOLO_URBAN_ISSUES_DATASET\\images\\train\n",
      "\n",
      "--- Checking Training Labels Directory ---\n",
      "ERROR: Training Labels directory does not exist at: D:\\Projects\\SIH\\YOLO_URBAN_ISSUES_DATASET\\YOLO_URBAN_ISSUES_DATASET\\labels\\train\n",
      "\n",
      "--- Diagnostic Complete ---\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# UPDATE THIS LINE with the absolute path you found in Step 1 \n",
    "# Example: DATASET_ROOT = r'D:\\Projects\\SIH\\urban_datasets' \n",
    "DATASET_ROOT = r'D:\\Projects\\SIH\\YOLO_URBAN_ISSUES_DATASET\\YOLO_URBAN_ISSUES_DATASET' # Starting with the current path as a guess\n",
    "\n",
    "# Initialize lists to avoid NameError if directories don't exist\n",
    "image_files = []\n",
    "label_files = []\n",
    "\n",
    "# Directories to check\n",
    "TRAIN_IMAGES_DIR = os.path.join(DATASET_ROOT, 'images', 'train')\n",
    "TRAIN_LABELS_DIR = os.path.join(DATASET_ROOT, 'labels', 'train')\n",
    "\n",
    "# 1. Check Image folder contents\n",
    "print(\"--- Checking Training Images Directory ---\")\n",
    "if not os.path.exists(TRAIN_IMAGES_DIR):\n",
    "    print(f\"ERROR: Training Images directory does not exist at: {TRAIN_IMAGES_DIR}\")\n",
    "else:\n",
    "    # Check if the path points to files or a directory containing files\n",
    "    image_files = [f for f in os.listdir(TRAIN_IMAGES_DIR) if f.lower().endswith(('.jpg', '.jpeg', '.png', '.bmp'))]\n",
    "    print(f\"Found {len(image_files)} image files in: {TRAIN_IMAGES_DIR}\")\n",
    "    if len(image_files) > 0:\n",
    "        print(f\"   First 3 files: {image_files[:3]}\")\n",
    "\n",
    "# 2. Check Labels folder contents\n",
    "print(\"\\n--- Checking Training Labels Directory ---\")\n",
    "if not os.path.exists(TRAIN_LABELS_DIR):\n",
    "    print(f\"ERROR: Training Labels directory does not exist at: {TRAIN_LABELS_DIR}\")\n",
    "else:\n",
    "    label_files = [f for f in os.listdir(TRAIN_LABELS_DIR) if f.lower().endswith('.txt')]\n",
    "    print(f\"Found {len(label_files)} label files in: {TRAIN_LABELS_DIR}\")\n",
    "    if len(label_files) > 0:\n",
    "        print(f\"   First 3 files: {label_files[:3]}\")\n",
    "\n",
    "# 3. Final Check: Image/Label Count Match\n",
    "if len(image_files) > 0 and len(label_files) > 0 and len(image_files) != len(label_files):\n",
    "    print(f\"\\nWARNING: Image count ({len(image_files)}) does not match label count ({len(label_files)}).\")\n",
    "    print(\"This will cause training errors later, but not the current FileNotFoundError.\")\n",
    "elif len(image_files) == 0 and os.path.exists(TRAIN_IMAGES_DIR):\n",
    "    print(\"\\nCRITICAL: The images/train folder exists but is EMPTY or contains only unsupported files.\")\n",
    "elif len(label_files) == 0 and os.path.exists(TRAIN_LABELS_DIR):\n",
    "    print(\"\\nCRITICAL: The labels/train folder exists but is EMPTY or missing .txt files.\")\n",
    "\n",
    "print(\"\\n--- Diagnostic Complete ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1503a39b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOUND DATASET ROOT: YOLO_URBAN_ISSUES_DATASET\\YOLO_URBAN_ISSUES_DATASET\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "for root, dirs, files in os.walk(\"YOLO_URBAN_ISSUES_DATASET\"):\n",
    "    if \"images\" in dirs and \"labels\" in dirs:\n",
    "        print(\"FOUND DATASET ROOT:\", root)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf149285",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Projects\\Sahaay\\.venv\\Lib\\site-packages\\ultralytics\\nn\\tasks.py:732: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  ckpt = torch.load(file, map_location=\"cpu\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.4.6 available  Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.2.0  Python-3.12.6 torch-2.5.1+cu121 CPU (AMD Ryzen 5 7535HS with Radeon Graphics)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.pt, data=data.yaml, epochs=50, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=cpu, workers=8, project=None, name=train23, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs\\detect\\train23\n",
      "Overriding model.yaml nc=80 with nc=9\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1    753067  ultralytics.nn.modules.head.Detect           [9, [64, 128, 256]]           \n",
      "Model summary: 225 layers, 3012603 parameters, 3012587 gradients, 8.2 GFLOPs\n",
      "\n",
      "Transferred 319/355 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Projects\\Sahaay\\.venv\\Lib\\site-packages\\ultralytics\\engine\\trainer.py:261: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.scaler = torch.cuda.amp.GradScaler(enabled=self.amp)\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning D:\\Projects\\Sahaay\\YOLO_URBAN_ISSUES_DATASET\\YOLO_URBAN_ISSUES_DATASET\\labels\\train... 377 images, 49 backgrounds, 0 corrupt: 100%|██████████| 377/377 [00:01<00:00, 254.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  D:\\Projects\\Sahaay\\YOLO_URBAN_ISSUES_DATASET\\YOLO_URBAN_ISSUES_DATASET\\images\\train\\30717230707_cc09c3e457_b_jpg.rf.1d5a1334fabe41fd6f5f19a2d25ac002.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  D:\\Projects\\Sahaay\\YOLO_URBAN_ISSUES_DATASET\\YOLO_URBAN_ISSUES_DATASET\\images\\train\\30717230707_cc09c3e457_b_jpg.rf.65c3ceebe756b8b3ab49c0987e78d404.jpg: 2 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  D:\\Projects\\Sahaay\\YOLO_URBAN_ISSUES_DATASET\\YOLO_URBAN_ISSUES_DATASET\\images\\train\\392C51FF00000578-0-image-a-11_1475781587245_jpg.rf.40a8bda830db6d5dba20687d03b78dc6.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  D:\\Projects\\Sahaay\\YOLO_URBAN_ISSUES_DATASET\\YOLO_URBAN_ISSUES_DATASET\\images\\train\\392C51FF00000578-0-image-a-11_1475781587245_jpg.rf.c30fe8120eeb1110fbd36256c83ad6ad.jpg: 2 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  D:\\Projects\\Sahaay\\YOLO_URBAN_ISSUES_DATASET\\YOLO_URBAN_ISSUES_DATASET\\images\\train\\AdobeStock_399405401_jpeg.rf.02a410708ac253f90bc032d267d01c27.jpg: 4 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  D:\\Projects\\Sahaay\\YOLO_URBAN_ISSUES_DATASET\\YOLO_URBAN_ISSUES_DATASET\\images\\train\\AdobeStock_399405401_jpeg.rf.11d99d12d42b8c0df16d7fb980ce5b30.jpg: 5 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  D:\\Projects\\Sahaay\\YOLO_URBAN_ISSUES_DATASET\\YOLO_URBAN_ISSUES_DATASET\\images\\train\\AdobeStock_399405401_jpeg.rf.71943b984a7a9290b7e28cf8010149c1.jpg: 6 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  D:\\Projects\\Sahaay\\YOLO_URBAN_ISSUES_DATASET\\YOLO_URBAN_ISSUES_DATASET\\images\\train\\Illegally-Parked-Car_jpg.rf.56eca7515fa784dbc8939afd25ca6325.jpg: 2 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  D:\\Projects\\Sahaay\\YOLO_URBAN_ISSUES_DATASET\\YOLO_URBAN_ISSUES_DATASET\\images\\train\\Illegally-Parked-Car_jpg.rf.b602cffeebe17670849b49545631480c.jpg: 3 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  D:\\Projects\\Sahaay\\YOLO_URBAN_ISSUES_DATASET\\YOLO_URBAN_ISSUES_DATASET\\images\\train\\Illegally-Parked-Car_jpg.rf.be95213f70708685c46ba2830077862b.jpg: 4 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  D:\\Projects\\Sahaay\\YOLO_URBAN_ISSUES_DATASET\\YOLO_URBAN_ISSUES_DATASET\\images\\train\\a61a0fdd678a0c9b3f3d8ddc1bad34a0_jpg.rf.5b23d09bd926e64bf97b2593e72d8d3f.jpg: 2 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  D:\\Projects\\Sahaay\\YOLO_URBAN_ISSUES_DATASET\\YOLO_URBAN_ISSUES_DATASET\\images\\train\\a61a0fdd678a0c9b3f3d8ddc1bad34a0_jpg.rf.9415dd3f7ec1ed34170857665964e5f9.jpg: 3 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  D:\\Projects\\Sahaay\\YOLO_URBAN_ISSUES_DATASET\\YOLO_URBAN_ISSUES_DATASET\\images\\train\\a61a0fdd678a0c9b3f3d8ddc1bad34a0_jpg.rf.fffd277cb8af700689c2be1cb2e0d43e.jpg: 4 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  D:\\Projects\\Sahaay\\YOLO_URBAN_ISSUES_DATASET\\YOLO_URBAN_ISSUES_DATASET\\images\\train\\gdq9mizqmgd91_jpg.rf.bf3aef9dc491fa0c498bef6dbacef3e4.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  D:\\Projects\\Sahaay\\YOLO_URBAN_ISSUES_DATASET\\YOLO_URBAN_ISSUES_DATASET\\images\\train\\gdq9mizqmgd91_jpg.rf.eb7c67b04846f8591d6d583e21087501.jpg: 2 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  D:\\Projects\\Sahaay\\YOLO_URBAN_ISSUES_DATASET\\YOLO_URBAN_ISSUES_DATASET\\images\\train\\images-4_jpeg.rf.1fcdabde97a31c33f316687b76ed18dc.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  D:\\Projects\\Sahaay\\YOLO_URBAN_ISSUES_DATASET\\YOLO_URBAN_ISSUES_DATASET\\images\\train\\images-4_jpeg.rf.be8d6850db4e1a426729a260faaf4ee5.jpg: 2 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  D:\\Projects\\Sahaay\\YOLO_URBAN_ISSUES_DATASET\\YOLO_URBAN_ISSUES_DATASET\\images\\train\\images_jpeg.rf.8540ebe6e67c455c32e2ae95fdda20ca.jpg: 2 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  D:\\Projects\\Sahaay\\YOLO_URBAN_ISSUES_DATASET\\YOLO_URBAN_ISSUES_DATASET\\images\\train\\images_jpeg.rf.8d81194470ea2a4b8caaa76ad8fed9bd.jpg: 3 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  D:\\Projects\\Sahaay\\YOLO_URBAN_ISSUES_DATASET\\YOLO_URBAN_ISSUES_DATASET\\images\\train\\images_jpeg.rf.931cc99877baf2c8ee7ae69c66cbf3cb.jpg: 4 duplicate labels removed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: D:\\Projects\\Sahaay\\YOLO_URBAN_ISSUES_DATASET\\YOLO_URBAN_ISSUES_DATASET\\labels\\train.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning D:\\Projects\\Sahaay\\YOLO_URBAN_ISSUES_DATASET\\YOLO_URBAN_ISSUES_DATASET\\labels\\val... 66 images, 13 backgrounds, 0 corrupt: 100%|██████████| 66/66 [00:00<00:00, 216.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: D:\\Projects\\Sahaay\\YOLO_URBAN_ISSUES_DATASET\\YOLO_URBAN_ISSUES_DATASET\\labels\\val.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs\\detect\\train23\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000769, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1mruns\\detect\\train23\u001b[0m\n",
      "Starting training for 50 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/50         0G      1.716      4.008      1.812         22        640: 100%|██████████| 24/24 [02:12<00:00,  5.53s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:10<00:00,  3.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         66         72    0.00701       0.75      0.125      0.072\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/50         0G      1.572      3.583      1.707         47        640: 100%|██████████| 24/24 [02:12<00:00,  5.54s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:09<00:00,  3.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         66         72    0.00316      0.774      0.213       0.12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       3/50         0G      1.614      3.227       1.75         25        640: 100%|██████████| 24/24 [02:12<00:00,  5.51s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:09<00:00,  3.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         66         72      0.777     0.0848      0.104     0.0606\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       4/50         0G      1.539       2.94      1.723         26        640: 100%|██████████| 24/24 [02:18<00:00,  5.76s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:09<00:00,  3.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         66         72      0.518      0.215      0.213      0.117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       5/50         0G      1.606      2.975      1.771         23        640: 100%|██████████| 24/24 [02:12<00:00,  5.54s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:08<00:00,  2.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         66         72      0.611       0.27      0.172     0.0791\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       6/50         0G      1.658      2.866      1.825         38        640: 100%|██████████| 24/24 [02:11<00:00,  5.48s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:09<00:00,  3.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         66         72      0.587      0.347       0.31       0.19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       7/50         0G      1.602      2.741      1.775         40        640: 100%|██████████| 24/24 [02:09<00:00,  5.40s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:08<00:00,  2.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         66         72      0.493      0.214      0.218      0.127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       8/50         0G      1.574      2.639       1.75         38        640: 100%|██████████| 24/24 [02:09<00:00,  5.38s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:08<00:00,  2.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         66         72      0.474      0.242      0.197      0.127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       9/50         0G      1.511      2.483      1.687         34        640: 100%|██████████| 24/24 [02:09<00:00,  5.38s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:08<00:00,  2.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         66         72      0.386      0.269       0.24      0.101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      10/50         0G      1.537       2.37      1.679         28        640: 100%|██████████| 24/24 [02:09<00:00,  5.39s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:08<00:00,  2.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         66         72      0.351      0.261      0.168     0.0841\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      11/50         0G      1.472      2.319      1.636         23        640: 100%|██████████| 24/24 [02:10<00:00,  5.44s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:08<00:00,  2.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         66         72        0.6      0.186      0.185     0.0969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      12/50         0G      1.511      2.275      1.625         22        640: 100%|██████████| 24/24 [02:10<00:00,  5.43s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:08<00:00,  2.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         66         72       0.74       0.19      0.209      0.106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      13/50         0G      1.429      2.185      1.611         23        640: 100%|██████████| 24/24 [02:07<00:00,  5.31s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:08<00:00,  2.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         66         72      0.526       0.31       0.23      0.128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      14/50         0G      1.446       2.18      1.598         35        640: 100%|██████████| 24/24 [02:09<00:00,  5.41s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:08<00:00,  2.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         66         72      0.342      0.232      0.185     0.0762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      15/50         0G      1.395      2.064      1.585         43        640: 100%|██████████| 24/24 [02:10<00:00,  5.46s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:08<00:00,  2.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         66         72        0.4      0.285      0.262      0.168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      16/50         0G      1.386      2.071      1.573         31        640: 100%|██████████| 24/24 [02:09<00:00,  5.41s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:08<00:00,  2.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         66         72      0.437      0.412      0.372      0.237\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      17/50         0G      1.364      1.928      1.549         35        640: 100%|██████████| 24/24 [02:08<00:00,  5.34s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:08<00:00,  2.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         66         72      0.565      0.371      0.454      0.294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      18/50         0G      1.331      1.832      1.516         39        640: 100%|██████████| 24/24 [02:08<00:00,  5.36s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:07<00:00,  2.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         66         72      0.704      0.387      0.397      0.257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/24 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
    "\n",
    "from ultralytics import YOLO\n",
    "\n",
    "model = YOLO(\"yolov8n.pt\")\n",
    "\n",
    "model.train(\n",
    "    data=\"data.yaml\",\n",
    "    epochs=50,\n",
    "    imgsz=640,\n",
    "    batch=16,\n",
    "    device=\"cpu\"  \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cc21d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mkdir sr_models\n",
    "\n",
    "## The -L flag handles redirects, and -o specifies the output filename/path\n",
    "# curl -L -o sr_models/EDSR_x4.pb https://github.com/opencv/opencv_extra/raw/master/testdata/dnn_superres/EDSR_x4.pb\n",
    "\n",
    "# echo \"Downloaded EDSR_x4.pb to sr_models/ folder.\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
