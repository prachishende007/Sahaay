{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "08f5581d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists at sr_models\\EDSR_x4.pb. Skipping download.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "\n",
    "# 1. Define paths and URL\n",
    "SR_MODEL_DIR = 'sr_models'\n",
    "SR_MODEL_PATH = os.path.join(SR_MODEL_DIR, 'EDSR_x4.pb')\n",
    "SR_MODEL_URL = 'https://github.com/opencv/opencv_extra/raw/master/testdata/dnn_superres/EDSR_x4.pb'\n",
    "\n",
    "# 2. Create the directory if it doesn't exist\n",
    "os.makedirs(SR_MODEL_DIR, exist_ok=True)\n",
    "\n",
    "# 3. Check if the file already exists\n",
    "if os.path.exists(SR_MODEL_PATH):\n",
    "    print(f\"File already exists at {SR_MODEL_PATH}. Skipping download.\")\n",
    "else:\n",
    "    print(f\"Downloading Super-Resolution model from {SR_MODEL_URL}...\")\n",
    "    try:\n",
    "        # Get the content from the URL\n",
    "        response = requests.get(SR_MODEL_URL, stream=True)\n",
    "        response.raise_for_status() # Raise an HTTPError for bad responses (4xx or 5xx)\n",
    "\n",
    "        # Write the content to the local file\n",
    "        with open(SR_MODEL_PATH, 'wb') as f:\n",
    "            for chunk in response.iter_content(chunk_size=8192):\n",
    "                f.write(chunk)\n",
    "        \n",
    "        print(f\"Download complete. File saved to: {SR_MODEL_PATH}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred during download. You might need to install 'requests': pip install requests\")\n",
    "        print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "383a07f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenCV Version: 4.12.0\n",
      "Success! 'dnn_superres' module is available.\n",
      "Test successful: DnnSuperResImpl_create() ran without error.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "# Check the version (should be 4.x)\n",
    "print(f\"OpenCV Version: {cv2.__version__}\")\n",
    "\n",
    "# This check should now be True\n",
    "if hasattr(cv2, 'dnn_superres'):\n",
    "    print(\"Success! 'dnn_superres' module is available.\")\n",
    "else:\n",
    "    print(\"Error: 'dnn_superres' is still not available.\")\n",
    "\n",
    "# You can also try to create the object directly\n",
    "try:\n",
    "    sr = cv2.dnn_superres.DnnSuperResImpl_create()\n",
    "    print(\"Test successful: DnnSuperResImpl_create() ran without error.\")\n",
    "except AttributeError as e:\n",
    "    print(f\"Test failed even after reinstall: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2dd0291e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "from ultralytics import YOLO\n",
    "\n",
    "def fast_video_yolo_sr(\n",
    "    input_video,\n",
    "    output_video,\n",
    "    yolo_model_path,\n",
    "    scale=2,\n",
    "    skip_frames=2\n",
    "):\n",
    "    model = YOLO(yolo_model_path)\n",
    "\n",
    "    cap = cv2.VideoCapture(input_video)\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    w = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    h = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "    out = cv2.VideoWriter(\n",
    "        output_video,\n",
    "        cv2.VideoWriter_fourcc(*\"mp4v\"),\n",
    "        fps,\n",
    "        (w * scale, h * scale)\n",
    "    )\n",
    "\n",
    "    frame_id = 0\n",
    "    last_results = None\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        frame_id += 1\n",
    "\n",
    "        # YOLO only every N frames\n",
    "        if frame_id % skip_frames == 0:\n",
    "            last_results = model(frame, verbose=False)\n",
    "\n",
    "        # Upscale fast using OpenCV (NOT EDSR)\n",
    "        up = cv2.resize(frame, None, fx=scale, fy=scale, interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "        if last_results:\n",
    "            for box in last_results[0].boxes:\n",
    "                x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "                x1 *= scale; y1 *= scale\n",
    "                x2 *= scale; y2 *= scale\n",
    "\n",
    "                cv2.rectangle(up, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "\n",
    "        out.write(up)\n",
    "\n",
    "    cap.release()\n",
    "    out.release()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8e89b863",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "\n",
    "def diagnose_video_pipeline(video_path):\n",
    "    issues = []\n",
    "\n",
    "    # Check video existence\n",
    "    if not os.path.exists(video_path):\n",
    "        return [\"Video file not found\"]\n",
    "\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        return [\"OpenCV cannot open the video\"]\n",
    "\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    w = cap.get(cv2.CAP_PROP_FRAME_WIDTH)\n",
    "    h = cap.get(cv2.CAP_PROP_FRAME_HEIGHT)\n",
    "\n",
    "    if fps <= 0:\n",
    "        issues.append(\"⚠ FPS is invalid\")\n",
    "    if w <= 0 or h <= 0:\n",
    "        issues.append(\"⚠ Frame dimensions invalid\")\n",
    "\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        issues.append(\"Cannot read frames\")\n",
    "    else:\n",
    "        if frame is None:\n",
    "            issues.append(\"Frame is None\")\n",
    "        if frame.ndim != 3:\n",
    "            issues.append(\"Frame is not color (BGR)\")\n",
    "\n",
    "    cap.release()\n",
    "\n",
    "    if not hasattr(cv2, \"dnn_superres\"):\n",
    "        issues.append(\" opencv-contrib-python not installed\")\n",
    "\n",
    "    return issues if issues else [\" Video pipeline looks healthy\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9e9d770c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Video pipeline looks healthy\n",
      " Video pipeline looks healthy\n",
      " Video pipeline looks healthy\n",
      " Video pipeline looks healthy\n"
     ]
    }
   ],
   "source": [
    "issues = diagnose_video_pipeline(\"Video.mp4\")\n",
    "for i in issues:\n",
    "    print(i)\n",
    "    issues = []\n",
    "\n",
    "issues = diagnose_video_pipeline(\"Video1.mp4\")\n",
    "for i in issues:\n",
    "    print(i)\n",
    "    issues = []\n",
    "\n",
    "issues = diagnose_video_pipeline(\"Video3.mp4\")\n",
    "for i in issues:\n",
    "    print(i)\n",
    "    issues = []\n",
    "\n",
    "issues = diagnose_video_pipeline(\"Video3.mp4\")\n",
    "for i in issues:\n",
    "    print(i)\n",
    "    issues = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b0b1797d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File size: 36.79 MB\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "model_path = \"sr_models/EDSR_x4.pb\"\n",
    "\n",
    "if not os.path.exists(model_path):\n",
    "    print(f\"Error: File does not exist at {model_path}\")\n",
    "else:\n",
    "    file_size = os.path.getsize(model_path)\n",
    "    print(f\"File size: {file_size / (1024*1024):.2f} MB\")\n",
    "    \n",
    "    if file_size < 100000: # If less than 100KB, it's likely HTML\n",
    "        print(\"Error: The file is too small. You likely downloaded an HTML page instead of the model.\")\n",
    "        with open(model_path, 'r', errors='ignore') as f:\n",
    "            first_line = f.readline()\n",
    "            if \"<!DOCTYPE html>\" in first_line or \"<html>\" in first_line:\n",
    "                print(\"   Confirmation: This is definitely an HTML file!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a698d0aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading EDSR_x4.pb (this may take a minute)...\n",
      "Success! File saved to: sr_models\\EDSR_x4.pb\n",
      "Verified File Size: 36.79 MB\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "\n",
    "def download_sr_model(model_name=\"EDSR_x4.pb\"):\n",
    "    # Ensure directory exists\n",
    "    os.makedirs(\"sr_models\", exist_ok=True)\n",
    "    \n",
    "    url = f\"https://github.com/Saafke/EDSR_TensorFlow/raw/master/models/{model_name}\"\n",
    "    save_path = os.path.join(\"sr_models\", model_name)\n",
    "    \n",
    "    print(f\"Downloading {model_name} (this may take a minute)...\")\n",
    "    \n",
    "    response = requests.get(url, stream=True)\n",
    "    if response.status_code == 200:\n",
    "        with open(save_path, 'wb') as f:\n",
    "            for chunk in response.iter_content(chunk_size=8192):\n",
    "                f.write(chunk)\n",
    "        \n",
    "        file_size = os.path.getsize(save_path)\n",
    "        print(f\"Success! File saved to: {save_path}\")\n",
    "        print(f\"Verified File Size: {file_size / (1024*1024):.2f} MB\")\n",
    "    else:\n",
    "        print(f\"Failed to download. Status code: {response.status_code}\")\n",
    "\n",
    "# Run the download\n",
    "download_sr_model(\"EDSR_x4.pb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4661ceb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "from collections import Counter\n",
    "\n",
    "# Internal reasoning map (SYSTEM LOGIC, not user input)\n",
    "ISSUE_MAPPING = {\n",
    "    \"Damaged concrete structures\": (\n",
    "        \"Structural damage in public infrastructure\",\n",
    "        \"Infrastructure damage monitoring system\"\n",
    "    ),\n",
    "    \"DamagedElectricalPoles\": (\n",
    "        \"Electrical pole damage posing public safety risk\",\n",
    "        \"Electrical infrastructure monitoring system\"\n",
    "    ),\n",
    "    \"DamagedRoadSigns\": (\n",
    "        \"Damaged or missing road signs affecting traffic safety\",\n",
    "        \"Traffic safety monitoring system\"\n",
    "    ),\n",
    "    \"DeadAnimalsPollution\": (\n",
    "        \"Dead animals causing hygiene and pollution issues\",\n",
    "        \"Sanitation and animal welfare system\"\n",
    "    ),\n",
    "    \"FallenTrees\": (\n",
    "        \"Fallen trees obstructing roads or walkways\",\n",
    "        \"Disaster response and urban safety system\"\n",
    "    ),\n",
    "    \"Garbage\": (\n",
    "        \"Improper garbage disposal in public areas\",\n",
    "        \"Smart waste management system\"\n",
    "    ),\n",
    "    \"Graffitti\": (\n",
    "        \"Vandalism detected on public property\",\n",
    "        \"Urban maintenance and vandalism detection system\"\n",
    "    ),\n",
    "    \"IllegalParking\": (\n",
    "        \"Vehicles illegally parked causing obstruction\",\n",
    "        \"Traffic enforcement and parking monitoring system\"\n",
    "    ),\n",
    "    \"Potholes and RoadCracks\": (\n",
    "        \"Road surface damage affecting commuter safety\",\n",
    "        \"Road condition and maintenance monitoring system\"\n",
    "    )\n",
    "}\n",
    "\n",
    "def analyze_issue_from_video(video_path, yolo_model_path, frame_skip=5, conf=0.4):\n",
    "    model = YOLO(yolo_model_path)\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "    if not cap.isOpened():\n",
    "        raise RuntimeError(\"Cannot open video\")\n",
    "\n",
    "    detected_classes = []\n",
    "    frame_id = 0\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        frame_id += 1\n",
    "        if frame_id % frame_skip != 0:\n",
    "            continue\n",
    "\n",
    "        results = model(frame, conf=conf, verbose=False)\n",
    "\n",
    "        for box in results[0].boxes:\n",
    "            cls_id = int(box.cls[0])\n",
    "            class_name = model.names[cls_id]   \n",
    "            detected_classes.append(class_name)\n",
    "\n",
    "    cap.release()\n",
    "\n",
    "    if not detected_classes:\n",
    "        return {\n",
    "            \"issue_detected\": \"No visible civic issue detected\",\n",
    "            \"built_for\": \"Urban monitoring system\",\n",
    "            \"confidence\": 0.0\n",
    "        }\n",
    "\n",
    "    counts = Counter(detected_classes)\n",
    "    dominant_class, freq = counts.most_common(1)[0]\n",
    "\n",
    "    issue, purpose = ISSUE_MAPPING.get(\n",
    "        dominant_class,\n",
    "        (\"General civic issue detected\", \"Civic issue monitoring system\")\n",
    "    )\n",
    "\n",
    "    confidence = round(freq / sum(counts.values()), 2)\n",
    "\n",
    "    return {\n",
    "        \"issue_detected\": issue,\n",
    "        \"built_for\": purpose,\n",
    "        \"dominant_issue_class\": dominant_class,\n",
    "        \"confidence\": confidence,\n",
    "        \"class_distribution\": dict(counts)\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "281fa48a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Projects\\SIH\\.venv\\Lib\\site-packages\\ultralytics\\nn\\tasks.py:732: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  ckpt = torch.load(file, map_location=\"cpu\")\n"
     ]
    }
   ],
   "source": [
    "fast_video_yolo_sr(\n",
    "    \"video3.mp4\",\n",
    "    \"output_video3.mp4\",\n",
    "    \"runs/detect/train20/weights/best.pt\",\n",
    "    scale=2,\n",
    "    skip_frames=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1d71daf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Projects\\SIH\\.venv\\Lib\\site-packages\\ultralytics\\nn\\tasks.py:732: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  ckpt = torch.load(file, map_location=\"cpu\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'issue_detected': 'Electrical pole damage posing public safety risk',\n",
       " 'built_for': 'Electrical infrastructure monitoring system',\n",
       " 'dominant_issue_class': 'DamagedElectricalPoles',\n",
       " 'confidence': 0.64,\n",
       " 'class_distribution': {'DamagedElectricalPoles': 58,\n",
       "  'Graffitti': 13,\n",
       "  'Garbage': 10,\n",
       "  'FallenTrees': 1,\n",
       "  'IllegalParking': 8}}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyze_issue_from_video(\"output_video2.mp4\", \"runs/detect/train20/weights/best.pt\", frame_skip=2, conf=0.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20f9f09e",
   "metadata": {},
   "source": [
    "### CodeSnap — analyze_issue_from_video call\n",
    "\n",
    "```python\n",
    "analyze_issue_from_video(\"output_video2.mp4\", \"runs/detect/train20/weights/best.pt\", frame_skip=2, conf=0.4)\n",
    "```\n",
    "\n",
    "- **Purpose:** Run YOLO detection over an output video and summarize the dominant civic issue.\n",
    "- **Notes:** Ensure the function definitions and model path are available before running this cell.\n",
    "- **Run:** Execute the preceding cells (functions/imports) then run this cell to get the analysis result."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
